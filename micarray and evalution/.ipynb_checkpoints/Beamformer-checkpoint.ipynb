{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as pp\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from  scipy.io import wavfile\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython import display\n",
    "from copy import deepcopy\n",
    "from scipy.signal import fftconvolve\n",
    "\n",
    "# the pra library\n",
    "import pyroomacoustics as pra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple wrapper class for (1-channel) audio data\n",
    "# data is a 1-D NumPy array containing the data\n",
    "# rate is a number expressing the samples per second\n",
    "class Audio:\n",
    "    def __init__(self, data, rate):\n",
    "        self.data = data\n",
    "        self.rate = rate\n",
    "    def play(self):\n",
    "        return display.Audio(self.data, rate=self.rate)\n",
    "    def plot_wave(self):\n",
    "        librosa.display.waveplot(self.data, sr=self.rate)\n",
    "    def plot_spectrum(self):\n",
    "        n_fft = int(self.rate / 20)\n",
    "        D = librosa.amplitude_to_db(np.abs(librosa.stft(self.data, n_fft)), ref=np.max)\n",
    "        librosa.display.specshow(D, y_axis='linear', sr=self.rate, hop_length=n_fft/4)\n",
    "    @classmethod\n",
    "    def fromfile(cls, fn):\n",
    "        return cls(*librosa.load(fn, sr=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flute = Audio.fromfile(\"../sounds/flute.wav\")\n",
    "flute.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symphony = Audio.fromfile(\"../sounds/symphony.wav\")\n",
    "symphony = Audio(symphony.data[:len(flute.data)], symphony.rate)\n",
    "symphony.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read1 = Audio.fromfile(\"../sounds/read.wav\")\n",
    "read1 = Audio(read1.data[:len(flute.data)], read1.rate)\n",
    "read1.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read2 = Audio.fromfile(\"../sounds/read2.wav\")\n",
    "read2 = Audio(read2.data[:len(flute.data)], read2.rate)\n",
    "read2.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = Audio.fromfile(\"../sounds/background_noise.wav\")\n",
    "background = Audio(background.data[:len(flute.data)], background.rate)\n",
    "background.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silence = Audio(np.asarray([0.0] * len(flute.data)), flute.rate)\n",
    "silence.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beamforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beamformer(mic_locs, target_loc):\n",
    "    Lg_t = 0.1 # filter size in seconds\n",
    "    Lg = np.ceil(Lg_t*48000)\n",
    "    \n",
    "    fft_len = 512\n",
    "    mics = pra.Beamformer(mic_locs, 48000, N=fft_len, Lg=Lg)\n",
    "    source = pra.soundsource.SoundSource([7, 1, 2])\n",
    "\n",
    "    mics.rake_delay_and_sum_weights(source)\n",
    "    mics.filters_from_weights()\n",
    "    return mics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic_locs = np.c_[\n",
    "    [1, 4.5, 5],\n",
    "    [1, 4.7, 5],\n",
    "    [1, 4.9, 5],\n",
    "    [1, 5.1, 5],\n",
    "    [1, 5.3, 5],\n",
    "    [1, 5.5, 5]\n",
    "]\n",
    "target_loc = [7, 1, 2]\n",
    "mics = beamformer(mic_locs, target_loc)\n",
    "mics.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beamforming(sound, noise):\n",
    "    '''Room Parameters and Room Creation'''\n",
    "    rt60 = 0.5\n",
    "    room_dim = [10, 10, 10] # meters\n",
    "    e_absorption, max_order = pra.inverse_sabine(rt60, room_dim)\n",
    "    # m = pra.Material(energy_absorption=\"panel_fabric_covered_6pcf\")\n",
    "    room = pra.ShoeBox(room_dim, fs=48000, materials=pra.Material(e_absorption), max_order=0) #simulate perfect situation: no reflections\n",
    "\n",
    "    '''Sound Source Creation'''\n",
    "    room.add_source([7, 1, 2], signal=sound)\n",
    "    room.add_source([8, 5, 5], signal=noise)\n",
    "\n",
    "    '''Mic Array Creation'''\n",
    "    mic_locs = np.c_[\n",
    "        [1, 4.5, 5],\n",
    "        [1, 4.7, 5],\n",
    "        [1, 4.9, 5],\n",
    "        [1, 5.1, 5],\n",
    "        [1, 5.3, 5],\n",
    "        [1, 5.5, 5]\n",
    "    ]\n",
    "\n",
    "#     mic_locs = np.c_[\n",
    "#         [1, 5, 5],\n",
    "#         [1, 5.5, 5],\n",
    "#         [1, 5, 5.5],\n",
    "#         [1, 5.5, 5.5]\n",
    "#     ]\n",
    "\n",
    "    # # center of array as column vector\n",
    "    # mic_center = np.c_[[1, 5, 5]]\n",
    "    # # microphone array radius\n",
    "    # mic_radius = 0.05\n",
    "    # # number of elements\n",
    "    # mic_n = 8\n",
    "    # # The GridSphere objects creates a number of points\n",
    "    # # pseudo-uniformly spread on the unit sphere\n",
    "    # grid = pra.doa.GridSphere(mic_n)\n",
    "    # # The locations of the microphones can then be computed\n",
    "    # mic_locs = mic_center + mic_radius * grid.cartesian\n",
    "\n",
    "    # filter size (???)\n",
    "    Lg_t = 0.1 # filter size in seconds\n",
    "    Lg = np.ceil(Lg_t*room.fs)\n",
    "\n",
    "\n",
    "    # place the beamforming micarray in the room (the beamforming class is a child class of the micarray class)\n",
    "    fft_len = 512\n",
    "    mics = pra.Beamformer(mic_locs, room.fs, N=fft_len, Lg=Lg)\n",
    "    room.add_microphone_array(mics)\n",
    "\n",
    "\n",
    "    # Compute DAS (delay and sum) weights\n",
    "    mics.rake_delay_and_sum_weights(room.sources[0])\n",
    "\n",
    "    '''Simulation'''\n",
    "    room.compute_rir()\n",
    "    room.simulate()\n",
    "    return room, mics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flute vs. Background noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room1, mics1 = beamforming(flute.data, background.data)\n",
    "fig, ax = room1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Original_mixed ###\n",
    "mix_audio = Audio(room1.mic_array.signals[0, :], room1.fs)\n",
    "mix_audio.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Beamformed ###\n",
    "bf_signal = mics1.process()\n",
    "bf_audio = Audio(bf_signal * np.linalg.norm(mix_audio.data) / np.linalg.norm(bf_signal.data), room1.fs)\n",
    "bf_audio.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customized Flute vs. Background noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = mics1.signals\n",
    "output = fftconvolve(mics.filters[0], signals[0])\n",
    "for i in range(1, len(signals)):\n",
    "    output += fftconvolve(mics.filters[i], signals[i])\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(output, flute.rate).play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
