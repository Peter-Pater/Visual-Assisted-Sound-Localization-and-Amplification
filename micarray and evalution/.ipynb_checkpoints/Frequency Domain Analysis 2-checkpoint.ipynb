{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as pp\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython import display\n",
    "from copy import deepcopy\n",
    "\n",
    "# the pra library\n",
    "import pyroomacoustics as pra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple wrapper class for (1-channel) audio data\n",
    "# data is a 1-D NumPy array containing the data\n",
    "# rate is a number expressing the samples per second\n",
    "class Audio:\n",
    "    def __init__(self, data, rate):\n",
    "        self.data = data\n",
    "        self.rate = rate\n",
    "    def play(self):\n",
    "        return display.Audio(self.data, rate=self.rate)\n",
    "    def plot_wave(self):\n",
    "        librosa.display.waveplot(self.data, sr=self.rate)\n",
    "    def plot_spectrum(self):\n",
    "        n_fft = int(self.rate / 20)\n",
    "        D = librosa.amplitude_to_db(np.abs(librosa.stft(self.data, n_fft)), ref=np.max)\n",
    "        librosa.display.specshow(D, y_axis='linear', sr=self.rate, hop_length=n_fft/4)\n",
    "    @classmethod\n",
    "    def fromfile(cls, fn):\n",
    "        return cls(*librosa.load(fn, sr=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flute = Audio.fromfile(\"../sounds/flute.wav\")\n",
    "flute.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symphony = Audio.fromfile(\"../sounds/symphony.wav\")\n",
    "symphony = Audio(symphony.data[:len(flute.data)], symphony.rate)\n",
    "symphony.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read1 = Audio.fromfile(\"../sounds/read.wav\")\n",
    "read1 = Audio(read1.data[:len(flute.data)], read1.rate)\n",
    "read1.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read2 = Audio.fromfile(\"../sounds/read2.wav\")\n",
    "read2 = Audio(read2.data[:len(flute.data)], read2.rate)\n",
    "read2.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = Audio.fromfile(\"../sounds/background_noise.wav\")\n",
    "background = Audio(background.data[:len(flute.data)], background.rate)\n",
    "background.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silence = Audio(np.asarray([0.0] * len(flute.data)), flute.rate)\n",
    "silence.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beamforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beamforming(sound, noise):\n",
    "    '''Room Parameters and Room Creation'''\n",
    "    rt60 = 0.5\n",
    "    room_dim = [10, 10, 10] # meters\n",
    "    e_absorption, max_order = pra.inverse_sabine(rt60, room_dim)\n",
    "    # m = pra.Material(energy_absorption=\"panel_fabric_covered_6pcf\")\n",
    "    room = pra.ShoeBox(room_dim, fs=48000, materials=pra.Material(e_absorption), max_order=0) #simulate perfect situation: no reflections\n",
    "\n",
    "    '''Sound Source Creation'''\n",
    "    room.add_source([7, 1, 2], signal=sound)\n",
    "    room.add_source([8, 5, 5], signal=noise)\n",
    "\n",
    "    '''Mic Array Creation'''\n",
    "    mic_locs = np.c_[\n",
    "        [1, 4.5, 5],\n",
    "        [1, 4.6, 5],\n",
    "        [1, 4.7, 5],\n",
    "        [1, 4.8, 5],\n",
    "        [1, 4.9, 5],\n",
    "#         [1, 5, 5],\n",
    "        [1, 5.1, 5],\n",
    "        [1, 5.2, 5],\n",
    "        [1, 5.3, 5],\n",
    "        [1, 5.4, 5],\n",
    "        [1, 5.5, 5]\n",
    "    ]\n",
    "\n",
    "#     mic_locs = np.c_[\n",
    "#         [1, 5, 5],\n",
    "#         [1, 5.5, 5],\n",
    "#         [1, 5, 5.5],\n",
    "#         [1, 5.5, 5.5]\n",
    "#     ]\n",
    "\n",
    "    # # center of array as column vector\n",
    "    # mic_center = np.c_[[1, 5, 5]]\n",
    "    # # microphone array radius\n",
    "    # mic_radius = 0.05\n",
    "    # # number of elements\n",
    "    # mic_n = 8\n",
    "    # # The GridSphere objects creates a number of points\n",
    "    # # pseudo-uniformly spread on the unit sphere\n",
    "    # grid = pra.doa.GridSphere(mic_n)\n",
    "    # # The locations of the microphones can then be computed\n",
    "    # mic_locs = mic_center + mic_radius * grid.cartesian\n",
    "\n",
    "    # filter size (???)\n",
    "    Lg_t = 0.1 # filter size in seconds\n",
    "    Lg = np.ceil(Lg_t*room.fs)\n",
    "\n",
    "\n",
    "    # place the beamforming micarray in the room (the beamforming class is a child class of the micarray class)\n",
    "    fft_len = 512\n",
    "    mics = pra.Beamformer(mic_locs, room.fs, N=fft_len, Lg=Lg)\n",
    "    room.add_microphone_array(mics)\n",
    "\n",
    "\n",
    "    # Compute DAS (delay and sum) weights\n",
    "    mics.rake_delay_and_sum_weights(room.sources[0])\n",
    "\n",
    "    '''Simulation'''\n",
    "    room.compute_rir()\n",
    "    room.simulate()\n",
    "    return room, mics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms(signal):\n",
    "    power = np.sum(np.asarray(signal) ** 2) / len(signal)\n",
    "    return power "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flute vs. background noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room, mics = beamforming(flute.data, background.data)\n",
    "fig, ax = room.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Original_mixed ###\n",
    "mix_audio = Audio(room.mic_array.signals[0, :], room.fs)\n",
    "mix_audio.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_audio.plot_wave()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_audio.plot_spectrum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Beamformed ###\n",
    "bf_signal = mics.process()\n",
    "bf_audio = Audio(bf_signal * np.linalg.norm(mix_audio.data) / np.linalg.norm(bf_signal.data), room.fs)\n",
    "# bf_audio = Audio(bf_signal, room.fs)\n",
    "bf_audio.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_audio.plot_wave()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_audio.plot_spectrum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flute vs. background noise: evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room, mics = beamforming(flute.data, silence.data)\n",
    "recv_flute = Audio(room.mic_array.signals[0, :], room.fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "construct_flute = mics.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room, mics = beamforming(silence.data, background.data)\n",
    "recv_background = Audio(room.mic_array.signals[0, :], room.fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deconstruct_noise = mics.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr1 = rms(recv_flute.data) / rms(recv_background.data)\n",
    "print(\"Original SNR:\", 10 * np.log10(snr1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr2 = rms(construct_flute) / rms(deconstruct_noise)\n",
    "print(\"Beamformed SNR:\", 10 * np.log10(snr2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flute vs. Symphony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room, mics = beamforming(flute.data, symphony.data)\n",
    "fig, ax = room.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Original_mixed ###\n",
    "mix_audio = Audio(room.mic_array.signals[0, :], room.fs)\n",
    "mix_audio.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_audio.plot_wave()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_audio.plot_spectrum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Beamformed ###\n",
    "bf_signal = mics.process()\n",
    "bf_audio = Audio(bf_signal * np.linalg.norm(mix_audio.data) / np.linalg.norm(bf_signal.data), room.fs)\n",
    "bf_audio.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_audio.plot_wave()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_audio.plot_spectrum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read vs. Background noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room, mics = beamforming(read1.data, background.data)\n",
    "fig, ax = room.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Original_mixed ###\n",
    "mix_audio = Audio(room.mic_array.signals[0, :], room.fs)\n",
    "mix_audio.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_audio.plot_wave()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_audio.plot_spectrum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Beamformed ###\n",
    "bf_signal = mics.process()\n",
    "bf_audio = Audio(bf_signal * np.linalg.norm(mix_audio.data) / np.linalg.norm(bf_signal.data), room.fs)\n",
    "bf_audio.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_audio.plot_wave()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_audio.plot_spectrum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read vs. Flute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room, mics = beamforming(read1.data, flute.data)\n",
    "fig, ax = room.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_audio = Audio(room.mic_array.signals[0, :], room.fs)\n",
    "mix_audio.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_audio.plot_wave()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_audio.plot_spectrum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Beamformed ###\n",
    "bf_signal = mics.process()\n",
    "bf_audio = Audio(bf_signal * np.linalg.norm(mix_audio.data) / np.linalg.norm(bf_signal.data), room.fs)\n",
    "bf_audio.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_audio.plot_wave()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_audio.plot_spectrum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read vs. Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room, mics = beamforming(read1.data, read2.data)\n",
    "fig, ax = room.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_audio = Audio(room.mic_array.signals[0, :], room.fs)\n",
    "mix_audio.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_audio.plot_wave()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_audio.plot_spectrum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_signal = mics.process()\n",
    "bf_audio = Audio(bf_signal * np.linalg.norm(mix_audio.data) / np.linalg.norm(bf_signal.data), room.fs)\n",
    "bf_audio.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_audio.plot_wave()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_audio.plot_spectrum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
